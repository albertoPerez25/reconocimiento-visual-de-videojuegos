{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fb85da0",
   "metadata": {},
   "source": [
    "# Libreta para entrenar al modelo ganador\n",
    "\n",
    "Esta libreta servir√° para entrenar al modelo ganador con el datasheet completo. La experimentaci√≥n con la inferencia de este modelo ser har√° en la libreta principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb06a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Configuraci√≥n de entorno\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "from transformers import TFViTModel\n",
    "from transformers import TFAutoModel\n",
    "from sklearn.utils import class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pathlib\n",
    "import PIL.Image\n",
    "import time\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import gc \n",
    "from tensorflow.keras import mixed_precision\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from IPython.display import clear_output, display\n",
    "from PIL import Image as PILImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a197ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2026\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "#mixed_precision.set_global_policy('mixed_float16') #baja uso de ram usando la mitad de precision en los float. \n",
    "\n",
    "FAST_EXEC = True\n",
    "GENERAL_EPOCHS = 20\n",
    "FAST_EPOCHS = 1\n",
    "if FAST_EXEC:\n",
    "    epochs_to_use = FAST_EPOCHS\n",
    "else:\n",
    "    epochs_to_use = GENERAL_EPOCHS\n",
    "\n",
    "if FAST_EXEC:\n",
    "    print(f\"MODO R√ÅPIDO ACTIVADO (FAST_EXEC = True)\")\n",
    "    print(f\"   Todas las √©pocas de entrenamiento se reducen\")\n",
    "\n",
    "print(\"Versi√≥n de TensorFlow:\",tf.__version__)\n",
    "print(\"Tipo implementacion de Keras:\",{tf.keras.__name__})\n",
    "print(f\"GPU Disponible: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150281d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "KAGGLE_PATH = '/kaggle/input/videojuegos-small-tfrec/tfrecords_small_dataset'\n",
    "# Ruta que tendria en local.\n",
    "LOCAL_PATH = './images_dataset' \n",
    "\n",
    "# Aunque las im√°genes son mayores, el primer modelo (MLP) funciona mejor con 64x64\n",
    "BATCH_SIZE = 64\n",
    "IMG_HEIGHT = 64\n",
    "IMG_WIDTH = 64\n",
    "\"\"\"BATCH_SIZE = 16\n",
    "IMG_HEIGHT = 480\n",
    "IMG_WIDTH = 854\"\"\"\n",
    "\n",
    "# Para saber si es Kaggle y cambiar la ruta del dataset buscamos 'KAGGLE_KERNEL_RUN_TYPE' en el entorno\n",
    "if os.environ.get('KAGGLE_KERNEL_RUN_TYPE'):\n",
    "    data_dir = KAGGLE_PATH\n",
    "    print(\"Ejecuci√≥n en Kaggle detectada. Ruta al dataset:\",data_dir)\n",
    "else:\n",
    "    data_dir = LOCAL_PATH\n",
    "    print(\"Ejecuci√≥n en un entorno local. Ruta al dataset:\",data_dir)\n",
    "\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "# Verificar estructura y contar archivos tfrec\n",
    "train_shards = list(data_dir.glob('train/*.tfrec'))\n",
    "val_shards = list(data_dir.glob('val/*.tfrec'))\n",
    "test_shards = list(data_dir.glob('test/*.tfrec'))\n",
    "\n",
    "total_shards = len(train_shards) + len(val_shards) + len(test_shards)\n",
    "\n",
    "print(f\"\\nResumen de TFRecords encontrados:\")\n",
    "print(f\" ‚îú‚îÄ Train shards: {len(train_shards)}\")\n",
    "print(f\" ‚îú‚îÄ Val shards:   {len(val_shards)}\")\n",
    "print(f\" ‚îî‚îÄ Test shards:  {len(test_shards)}\")\n",
    "print(f\"Total archivos .tfrec: {total_shards}\")\n",
    "\n",
    "# Cargar una imagen para ver si se lee bien\n",
    "if total_shards == 0:\n",
    "    print(\"No se han encontrado archivos .tfrec\")\n",
    "else:\n",
    "    # Cogemos el primer archivo que encontremos\n",
    "    sample_file = str(train_shards[0])\n",
    "    \n",
    "    print(f\"\\nInspeccionando primer archivo: {os.path.basename(sample_file)}...\")\n",
    "    \n",
    "    # Leemos un solo registro\n",
    "    raw_dataset = tf.data.TFRecordDataset(sample_file)\n",
    "    for raw_record in raw_dataset.take(1):\n",
    "        # Parseamos manualmente para ver qu√© hay dentro\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "        \n",
    "        # Extraer etiqueta\n",
    "        label = example.features.feature['label'].int64_list.value[0]\n",
    "        \n",
    "        # Extraer imagen y decodificar\n",
    "        img_raw = example.features.feature['image'].bytes_list.value[0]\n",
    "        img_tensor = tf.io.decode_jpeg(img_raw)\n",
    "        \n",
    "        print(f\" Lectura exitosa.\")\n",
    "        print(f\" - Etiqueta (int): {label}\")\n",
    "        print(f\" - Shape original guardado: {img_tensor.shape}\")\n",
    "        print(f\" - Tipo de dato: {img_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3bab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deben estar en orden alfab√©tico estricto, igual que como se crearon los TFRecords\n",
    "class_names = [\n",
    "    'AMONG_US', 'CONTRA', 'ELDEN_RING', 'GOD_OF_WAR_1', 'GTA_SAN_ANDREAS', 'GTA_V', 'HADES', \n",
    "    'HOLLOW_KNIGHT', 'MARIO_GALAXY', 'MARIO_KART_8', 'MINECRAFT', 'NEW_SUPER_MARIO_BROS', \n",
    "    'POKEMON_X_Y', 'RED_DEAD_REDEMPTION_2', 'SILENT_HILL_2', 'UNDERTALE'\n",
    "]\n",
    "\n",
    "# Lectura \n",
    "def parse_tfrecord_fn(example, target_size):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    image = tf.io.decode_jpeg(example['image'], channels=3)\n",
    "    image = tf.image.resize(image, target_size) # Redimensi√≥n din√°mica AQU√ç\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    label = example['label']\n",
    "    return image, label\n",
    "\n",
    "def get_dataset_from_tfrecords(tfrecords_dir, batch_size=64, target_size=(224, 224)):\n",
    "    filenames = tf.io.gfile.glob(f\"{tfrecords_dir}/*.tfrec\")\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=tf.data.AUTOTUNE)\n",
    "    \n",
    "    ignore_order = tf.data.Options()\n",
    "    ignore_order.experimental_deterministic = False\n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "\n",
    "    dataset = dataset.map(\n",
    "        lambda x: parse_tfrecord_fn(x, target_size), \n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    \n",
    "    dataset = dataset.shuffle(2000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f805c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = get_dataset_from_tfrecords(os.path.join(data_dir, 'train'), batch_size=BATCH_SIZE, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "val_ds = get_dataset_from_tfrecords(os.path.join(data_dir, 'val'), batch_size=BATCH_SIZE, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "test_ds = get_dataset_from_tfrecords(os.path.join(data_dir, 'test'), batch_size=BATCH_SIZE, target_size=(IMG_HEIGHT, IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18e1b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weights(train_ds):\n",
    "    \"\"\"\n",
    "    Extrae las etiquetas del dataset de entrenamiento y calcula los pesos\n",
    "    para equilibrar las clases durante el entrenamiento.\n",
    "    \"\"\"\n",
    "    print(\"Calculando pesos de las clases \")\n",
    "    \n",
    "    # Mapeamos el dataset para que solo devuelva las etiquetas y. Evita decodificar las im√°genes pesadas\n",
    "    train_labels_only = train_ds.map(lambda x, y: y)\n",
    "    \n",
    "    # Ahora iteramos sobre un dataset de solo enteros (muy ligero)\n",
    "    y_train = []\n",
    "    for label_batch in train_labels_only:\n",
    "        y_train.extend(label_batch.numpy())\n",
    "        \n",
    "    y_train = np.array(y_train)\n",
    "    classes = np.unique(y_train)\n",
    "    \n",
    "    weights = class_weight.compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=classes,\n",
    "        y=y_train\n",
    "    )\n",
    "    \n",
    "    class_weight_dict = dict(zip(classes, weights))\n",
    "    \n",
    "    print(\"Pesos calculados exitosamente.\")\n",
    "    return class_weight_dict\n",
    "\n",
    "class_weights = calculate_class_weights(train_ds)\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278632aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n auxiliar para cargar TODO el dataset junto para visualizarlo entero\n",
    "def get_full_dataset_for_eda(tfrecords_dir, batch_size=64, target_size=(64, 64)):\n",
    "    # \"*/*.tfrec\" busca dentro de train, val y test a la vez\n",
    "    filenames = tf.io.gfile.glob(f\"{tfrecords_dir}/*/*.tfrec\")\n",
    "    \n",
    "    print(f\"Cargando full_ds desde {len(filenames)} archivos TFRecord\")\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=tf.data.AUTOTUNE)\n",
    "    \n",
    "    dataset = dataset.map(\n",
    "        lambda x: parse_tfrecord_fn(x, target_size), \n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Generamos la variable full_ds\n",
    "full_ds = get_full_dataset_for_eda(data_dir, batch_size=BATCH_SIZE, target_size=(IMG_HEIGHT, IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8cf90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# 1. Usamos 'unbatch()' para sacar las im√°genes de los paquetes\n",
    "# 2. Usamos 'take(25)' para coger exactamente las que necesitamos\n",
    "# 3. Usamos enumerate para saber en qu√© posici√≥n (i) del subplot estamos\n",
    "for i, (image, label) in enumerate(train_ds.unbatch().take(25)):\n",
    "    \n",
    "    ax = plt.subplot(5, 5, i + 1)\n",
    "    \n",
    "    # Ya no necesitamos [i] porque 'image' es una sola foto, no un lote\n",
    "    plt.imshow(image.numpy().astype(\"uint8\"))\n",
    "    \n",
    "    # Manejo del label\n",
    "    label_index = int(label) \n",
    "    plt.title(class_names[label_index])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Imagenes de ejemplo del dataset\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "class_counts = {name: 0 for name in class_names}\n",
    "for _, labels in full_ds:\n",
    "    for label in labels:\n",
    "        class_name = class_names[int(label)]\n",
    "        class_counts[class_name] += 1\n",
    "\n",
    "# Lo hacemos con un dataframe, pues es mas facil hacer el plot.\n",
    "df_counts = pd.DataFrame(list(class_counts.items()), columns=['Class', 'Count'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bplot = sns.barplot(x='Count', y='Class', data=df_counts, palette='viridis', hue='Class')\n",
    "# tenemos que quitar la leyenda manualmente porque da error con legend=False\n",
    "if bplot.get_legend() is not None:\n",
    "    bplot.get_legend().remove()\n",
    "\n",
    "plt.title('Distribucion de imagenes en el dataset', fontsize=16)\n",
    "plt.xlabel('Numero de imagenes', fontsize=12)\n",
    "plt.ylabel('Clase', fontsize=12)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# a√±adimos el numero al final de la barra para verlo mejor\n",
    "for index, value in enumerate(df_counts['Count']):\n",
    "    plt.text(value + 50, index, str(value), va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "mean_count = df_counts['Count'].mean()\n",
    "std_count = df_counts['Count'].std()\n",
    "print(f\"Media de imagenes: {mean_count:.2f}\")\n",
    "print(f\"Desviacion estandar: {std_count:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fcc468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: entrenar el modelo y eso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d4b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba con im√°genes in-the-wild\n",
    "def visualize_wild_predictions(model, img_dir, classes, target_size=(224, 224)):\n",
    "    correct_predictions = []\n",
    "    incorrect_predictions = []\n",
    "\n",
    "    # Verificar si el directorio existe\n",
    "    if not os.path.exists(img_dir):\n",
    "        print(f\"‚ö†Ô∏è El directorio {img_dir} no existe.\")\n",
    "        return\n",
    "\n",
    "    # Recorremos las subcarpetas (que son las clases reales)\n",
    "    for class_folder in os.listdir(img_dir):\n",
    "        class_path = os.path.join(img_dir, class_folder)\n",
    "        \n",
    "        # Solo procesar si es un directorio\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "            \n",
    "        true_label = class_folder # La carpeta nos da la etiqueta real\n",
    "        \n",
    "        # Verificar si la carpeta corresponde a una clase conocida por el modelo\n",
    "        if true_label not in classes:\n",
    "            print(f\"‚ö†Ô∏è La carpeta '{true_label}' no est√° en la lista de clases del modelo. Se omitir√°.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"üìÇ Procesando carpeta: {true_label}...\")\n",
    "        \n",
    "        files = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.webp'))]\n",
    "        \n",
    "        for file in files:\n",
    "            img_path = os.path.join(class_path, file)\n",
    "            \n",
    "            try:\n",
    "                # Cargar y preprocesar imagen\n",
    "                img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n",
    "                img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "                img_array = img_array / 255.0  # Normalizaci√≥n\n",
    "                img_batch = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "                # Predicci√≥n\n",
    "                preds = model.predict(img_batch, verbose=0)\n",
    "                pred_idx = np.argmax(preds)\n",
    "                pred_label = classes[pred_idx]\n",
    "                confidence = np.max(preds) * 100\n",
    "\n",
    "                result_data = {\n",
    "                    'filename': file,\n",
    "                    'img': img,\n",
    "                    'true': true_label,\n",
    "                    'pred': pred_label,\n",
    "                    'conf': confidence\n",
    "                }\n",
    "\n",
    "                if pred_label == true_label:\n",
    "                    correct_predictions.append(result_data)\n",
    "                else:\n",
    "                    incorrect_predictions.append(result_data)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error procesando {file}: {e}\")\n",
    "\n",
    "    # --- FUNCI√ìN AUXILIAR PARA PINTAR ---\n",
    "    def plot_grid(data_list, title, color_theme):\n",
    "        if not data_list:\n",
    "            print(f\"No hay im√°genes para mostrar en: {title}\")\n",
    "            return\n",
    "            \n",
    "        n = len(data_list)\n",
    "        cols = 5\n",
    "        rows = (n // cols) + 1 if n % cols != 0 else n // cols\n",
    "        \n",
    "        plt.figure(figsize=(15, 3.5 * rows))\n",
    "        plt.suptitle(title, fontsize=16, weight='bold', color=color_theme, y=1.02)\n",
    "        \n",
    "        for i, item in enumerate(data_list):\n",
    "            ax = plt.subplot(rows, cols, i + 1)\n",
    "            ax.imshow(item['img'])\n",
    "            ax.axis('off')\n",
    "            \n",
    "            # Formato del t√≠tulo de cada imagen\n",
    "            if title.startswith(\"FALLOS\"):\n",
    "                info_text = f\"Pred: {item['pred']}\\nConf: {item['conf']:.1f}%\\nReal: {item['true']}\"\n",
    "                txt_color = 'red'\n",
    "            else:\n",
    "                info_text = f\"{item['pred']}\\n{item['conf']:.1f}%\"\n",
    "                txt_color = 'green'\n",
    "                \n",
    "            ax.set_title(info_text, color=txt_color, fontsize=10)\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Mostrar resultados\n",
    "    print(f\"\\nResultados: {len(correct_predictions)} aciertos, {len(incorrect_predictions)} fallos.\")\n",
    "    \n",
    "    plot_grid(correct_predictions, \"ACIERTOS (Predicciones Correctas)\", 'green')\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    plot_grid(incorrect_predictions, \"FALLOS (Confusiones)\", 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfe8159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver predicciones en tiempo real de un v√≠deo\n",
    "def process_and_display_video(video_path, model, classes, target_size):\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"‚ö†Ô∏è No se encontr√≥ el video: {video_path}\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    def predict_frame(model, frame, classes, target_size):\n",
    "        \"\"\"\n",
    "        Funci√≥n auxiliar tipo predict_top_k adaptada para un solo frame.\n",
    "        Devuelve la etiqueta, la confianza y las top 3 probabilidades.\n",
    "        \"\"\"\n",
    "        # Preprocesamiento\n",
    "        # 1. Resize\n",
    "        img_resized = cv2.resize(frame, target_size)\n",
    "        # 2. Convertir a array y expandir dimensiones\n",
    "        img_array = np.array(img_resized, dtype=\"float32\")\n",
    "        # 3. Normalizar (Asumiendo que entrenaste con rescale 1./255)\n",
    "        img_array = img_array / 255.0\n",
    "        img_batch = np.expand_dims(img_array, axis=0)\n",
    "        \n",
    "        # Predicci√≥n\n",
    "        preds = model.predict(img_batch, verbose=0)[0]\n",
    "        \n",
    "        # Obtener Top K (Top 3 para visualizaci√≥n)\n",
    "        top_k_indices = preds.argsort()[-3:][::-1]\n",
    "        top_predictions = [(classes[i], preds[i] * 100) for i in top_k_indices]\n",
    "        \n",
    "        return top_predictions\n",
    "    \n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break # Fin del video\n",
    "\n",
    "            # --- L√ìGICA DE PREDICCI√ìN ---\n",
    "            # Para mejorar el rendimiento, puedes predecir cada N frames\n",
    "            # Aqu√≠ lo hacemos en todos para m√°xima fluidez visual\n",
    "            \n",
    "            # OpenCV usa BGR, Keras suele esperar RGB. Convertimos para la predicci√≥n.\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            top_preds = predict_frame(model, frame_rgb, classes, target_size)\n",
    "            \n",
    "            winner_label, winner_conf = top_preds[0]\n",
    "\n",
    "            # --- VISUALIZACI√ìN EN EL VIDEO ---\n",
    "            # Dibujar un rect√°ngulo de fondo para el texto\n",
    "            overlay = frame.copy()\n",
    "            cv2.rectangle(overlay, (0, 0), (300, 120), (0, 0, 0), -1)\n",
    "            alpha = 0.6 # Transparencia del fondo\n",
    "            frame = cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0)\n",
    "\n",
    "            # Escribir la predicci√≥n ganadora\n",
    "            color = (0, 255, 0) if winner_conf > 60 else (0, 165, 255) # Verde si seguro, Naranja si duda\n",
    "            \n",
    "            # T√≠tulo principal\n",
    "            cv2.putText(frame, f\"{winner_label}\", (10, 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame, f\"Conf: {winner_conf:.1f}%\", (10, 70), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "            # Mostrar la 2da opci√≥n peque√±a abajo (para ver si duda)\n",
    "            sec_label, sec_conf = top_preds[1]\n",
    "            cv2.putText(frame, f\"Alt: {sec_label} ({sec_conf:.1f}%)\", (10, 100), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1, cv2.LINE_AA)\n",
    "\n",
    "            # --- MOSTRAR EN JUPYTER ---\n",
    "            # Convertir BGR a RGB para mostrar correctamente con PIL\n",
    "            frame_display = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img_display = PILImage.fromarray(frame_display)\n",
    "            \n",
    "            # Truco para actualizar la celda: borrar salida anterior y mostrar nueva\n",
    "            clear_output(wait=True)\n",
    "            display(img_display)\n",
    "            \n",
    "            # Control de velocidad (opcional, quitar para ir a m√°xima velocidad)\n",
    "            # time.sleep(0.01) \n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"üõë Video detenido por el usuario.\")\n",
    "    finally:\n",
    "        cap.release()\n",
    "        print(\"Fin de la simulaci√≥n.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b199b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de robustez\n",
    "def robustness_test(model, base_dir, classes, target_size):\n",
    "    if not os.path.exists(base_dir):\n",
    "        print(f\"‚ö†Ô∏è Directorio {base_dir} no encontrado.\")\n",
    "        return\n",
    "\n",
    "    def add_gaussian_noise(image, sigma):\n",
    "        \"\"\"A√±ade ruido gaussiano a una imagen normalizada (0-1).\"\"\"\n",
    "        if sigma == 0: return image\n",
    "        noise = np.random.normal(0, sigma, image.shape)\n",
    "        noisy_image = image + noise\n",
    "        return np.clip(noisy_image, 0.0, 1.0) # Asegurar rango v√°lido\n",
    "\n",
    "    def apply_blur(image, kernel_size):\n",
    "        \"\"\"Aplica desenfoque gaussiano.\"\"\"\n",
    "        if kernel_size <= 1: return image\n",
    "        # Convertir a formato compatible con OpenCV si es necesario, pero cv2 soporta floats\n",
    "        return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "\n",
    "    def predict_single(model, img_array, classes):\n",
    "        \"\"\"Realiza la predicci√≥n sobre una imagen procesada.\"\"\"\n",
    "        img_batch = np.expand_dims(img_array, axis=0)\n",
    "        preds = model.predict(img_batch, verbose=0)\n",
    "        idx = np.argmax(preds)\n",
    "        return classes[idx], np.max(preds) * 100\n",
    "\n",
    "    # Iterar por cada clase (carpeta)\n",
    "    for class_folder in sorted(os.listdir(base_dir)):\n",
    "        folder_path = os.path.join(base_dir, class_folder)\n",
    "        if not os.path.isdir(folder_path): continue\n",
    "        \n",
    "        true_label = class_folder\n",
    "        if true_label not in classes: continue\n",
    "\n",
    "        # Buscar la imagen en la carpeta\n",
    "        files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        if not files:\n",
    "            print(f\"‚ö†Ô∏è No hay im√°genes en {true_label}\")\n",
    "            continue\n",
    "            \n",
    "        img_path = os.path.join(folder_path, files[0]) # Cogemos la primera/√∫nica imagen\n",
    "        \n",
    "        # Cargar y preprocesar imagen base\n",
    "        original_img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n",
    "        original_array = tf.keras.preprocessing.image.img_to_array(original_img)\n",
    "        original_array /= 255.0 # Normalizar a 0-1\n",
    "        \n",
    "        print(f\"\\n--- Evaluando Robustez para: {true_label} ---\")\n",
    "        \n",
    "        # Preparamos los plots\n",
    "        fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "        fig.suptitle(f\"Prueba de Estr√©s: {true_label}\", fontsize=16, weight='bold')\n",
    "\n",
    "        # --- FILA 1: RUIDO GAUSSIANO ---\n",
    "        for i, sigma in enumerate(NOISE_LEVELS):\n",
    "            img_noisy = add_gaussian_noise(original_array, sigma)\n",
    "            pred_lbl, conf = predict_single(model, img_noisy, classes)\n",
    "            \n",
    "            ax = axes[0, i]\n",
    "            ax.imshow(img_noisy)\n",
    "            ax.axis('off')\n",
    "            \n",
    "            color = 'green' if pred_lbl == true_label else 'red'\n",
    "            title_text = f\"Ruido: {sigma}\\nPred: {pred_lbl}\\nConf: {conf:.1f}%\"\n",
    "            ax.set_title(title_text, color=color, fontsize=10)\n",
    "\n",
    "        axes[0, 0].set_ylabel(\"Ruido\", fontsize=12, rotation=0, labelpad=40, weight='bold')\n",
    "\n",
    "        # --- FILA 2: DESENFOQUE (BLUR) ---\n",
    "        for i, k_size in enumerate(BLUR_LEVELS):\n",
    "            img_blurred = apply_blur(original_array, k_size)\n",
    "            pred_lbl, conf = predict_single(model, img_blurred, classes)\n",
    "            \n",
    "            ax = axes[1, i]\n",
    "            ax.imshow(img_blurred)\n",
    "            ax.axis('off')\n",
    "            \n",
    "            color = 'green' if pred_lbl == true_label else 'red'\n",
    "            blur_label = \"Original\" if k_size == 1 else f\"Blur (k={k_size})\"\n",
    "            title_text = f\"{blur_label}\\nPred: {pred_lbl}\\nConf: {conf:.1f}%\"\n",
    "            ax.set_title(title_text, color=color, fontsize=10)\n",
    "\n",
    "        axes[1, 0].set_ylabel(\"Blur\", fontsize=12, rotation=0, labelpad=40, weight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42ed4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejecutar_visualizacion_capas(model, img_dir, target_size, num_images=3):\n",
    "    \"\"\"\n",
    "    Funci√≥n maestra que selecciona im√°genes aleatorias de un directorio dado\n",
    "    y visualiza qu√© detectan las primeras y √∫ltimas capas convolucionales del modelo.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Funci√≥n interna auxiliar para procesar una sola imagen ---\n",
    "    def _visualizar_una_imagen(modelo_base, ruta_imagen):\n",
    "        try:\n",
    "            # 1. Cargar imagen\n",
    "            img = tf.keras.preprocessing.image.load_img(ruta_imagen, target_size=target_size)\n",
    "            x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "            x = x / 255.0\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "\n",
    "            # 2. Detectar capas convolucionales\n",
    "            # Si el modelo usa Transfer Learning (ej. MobileNet), las capas est√°n anidadas\n",
    "            motor_modelo = modelo_base\n",
    "            if isinstance(modelo_base.layers[0], tf.keras.Model):\n",
    "                motor_modelo = modelo_base.layers[0]\n",
    "\n",
    "            conv_layers = [layer for layer in motor_modelo.layers if 'conv' in layer.name]\n",
    "            \n",
    "            if not conv_layers:\n",
    "                print(\"‚ö†Ô∏è No se encontraron capas convolucionales.\")\n",
    "                return\n",
    "\n",
    "            # Seleccionamos la PRIMERA (texturas/bordes) y la √öLTIMA (sem√°ntica/formas)\n",
    "            capas_seleccionadas = [conv_layers[0], conv_layers[-1]]\n",
    "            nombres_capas = [layer.name for layer in capas_seleccionadas]\n",
    "            \n",
    "            # Crear un mini-modelo que devuelva solo las salidas de estas capas\n",
    "            extractor = tf.keras.models.Model(inputs=motor_modelo.inputs, \n",
    "                                            outputs=[layer.output for layer in capas_seleccionadas])\n",
    "\n",
    "            # 3. Obtener activaciones\n",
    "            activaciones = extractor.predict(x, verbose=0)\n",
    "            \n",
    "            # 4. Pintar resultados\n",
    "            print(f\"\\nüîπ Analizando: {os.path.basename(ruta_imagen)}\")\n",
    "            \n",
    "            # Mostrar original peque√±a\n",
    "            plt.figure(figsize=(3, 3))\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Entrada Original\", fontsize=10)\n",
    "            plt.show()\n",
    "\n",
    "            titulos = [\"PRIMERAS CAPAS (Bordes/Texturas)\", \"√öLTIMAS CAPAS (Sem√°ntica/Abstracto)\"]\n",
    "            \n",
    "            for nombre_capa, activacion, titulo in zip(nombres_capas, activaciones, titulos):\n",
    "                # La activaci√≥n tiene forma (1, alto, ancho, canales)\n",
    "                n_filtros = min(16, activacion.shape[-1]) # M√°ximo 16 filtros para no saturar\n",
    "                size = activacion.shape[1] \n",
    "                \n",
    "                n_cols = 4\n",
    "                n_rows = (n_filtros + n_cols - 1) // n_cols\n",
    "                \n",
    "                grid_img = np.zeros((size * n_rows, size * n_cols))\n",
    "\n",
    "                for i in range(n_rows):\n",
    "                    for j in range(n_cols):\n",
    "                        idx_filtro = i * n_cols + j\n",
    "                        if idx_filtro < n_filtros:\n",
    "                            filtro_img = activacion[0, :, :, idx_filtro]\n",
    "                            \n",
    "                            # Normalizaci√≥n visual para mejorar contraste\n",
    "                            if filtro_img.std() != 0:\n",
    "                                filtro_img -= filtro_img.mean()\n",
    "                                filtro_img /= filtro_img.std()\n",
    "                                filtro_img *= 64\n",
    "                                filtro_img += 128\n",
    "                            \n",
    "                            filtro_img = np.clip(filtro_img, 0, 255).astype('uint8')\n",
    "                            grid_img[i*size : (i+1)*size, j*size : (j+1)*size] = filtro_img\n",
    "\n",
    "                scale = 1.5\n",
    "                plt.figure(figsize=(scale * n_cols, scale * n_rows))\n",
    "                plt.title(f\"{titulo}\\nCapa: {nombre_capa}\", fontsize=12, weight='bold')\n",
    "                plt.imshow(grid_img, aspect='auto', cmap='viridis') \n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error visualizando {os.path.basename(ruta_imagen)}: {e}\")\n",
    "\n",
    "    # --- L√≥gica Principal ---\n",
    "    if not os.path.exists(img_dir):\n",
    "        print(f\"‚ö†Ô∏è El directorio {img_dir} no existe.\")\n",
    "        return\n",
    "\n",
    "    # Buscar im√°genes (solo nivel plano)\n",
    "    archivos = [os.path.join(img_dir, f) for f in os.listdir(img_dir) \n",
    "                if f.lower().endswith(('.png', '.jpg', '.jpeg', '.webp'))]\n",
    "\n",
    "    if archivos:\n",
    "        seleccion = random.sample(archivos, min(num_images, len(archivos)))\n",
    "        print(f\"--- Iniciando Visualizaci√≥n de Capas ({len(seleccion)} im√°genes) ---\")\n",
    "        for ruta in seleccion:\n",
    "            _visualizar_una_imagen(model, ruta)\n",
    "            print(\"-\" * 60)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è No hay im√°genes en {img_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaed9351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar experimentos\n",
    "MODEL_PATH = 'modelo_ganador.keras'\n",
    "TEST_IMAGES_DIR = 'ruta/a/tus/imagenes_in_the_wild'  # Carpeta con im√°genes in-the-wild\n",
    "TEST_SINGLE_IMG_DIR = 'ruta/a/carpeta_con_una_imagen_por_clase' # Carpeta con una imagen que predice correctamente por clase\n",
    "VIDEO_PATH = 'gameplay_clip.mp4'\n",
    "TEST2_IMAGES_DIR = 'ruta/a/tu_carpeta_test2_flat'\n",
    "TARGET_SIZE = (224, 224)\n",
    "\n",
    "# Niveles de intensidad para los experimentos\n",
    "# Ruido (Sigma para distribuci√≥n normal en im√°genes normalizadas 0-1)\n",
    "NOISE_LEVELS = [0.00, 0.05, 0.10, 0.20] \n",
    "# Desenfoque (Tama√±o del Kernel)\n",
    "BLUR_LEVELS = [1, 5, 11, 19]\n",
    "\n",
    "\n",
    "# Cargar el modelo ganador\n",
    "\n",
    "# Verificamos si el archivo existe antes de intentar cargarlo\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    try:\n",
    "        print(f\"Cargando modelo desde {MODEL_PATH}...\")\n",
    "        \n",
    "        # Es fundamental incluir 'SparseF1Score' en custom_objects porque el modelo\n",
    "        # se compil√≥ usando esta m√©trica personalizada.\n",
    "        final_model = load_model(MODEL_PATH, custom_objects={'SparseF1Score': SparseF1Score})\n",
    "        \n",
    "        print(\"Modelo ganador cargado correctamente\")\n",
    "        print(\"\\n--- Resumen del Modelo ---\")\n",
    "        final_model.summary()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar el modelo: {e}\")\n",
    "else:\n",
    "    print(f\"No se encontr√≥ el archivo en: {MODEL_PATH}\")\n",
    "    print(\"Por favor, sube el archivo del modelo (.keras) y actualiza la variable MODEL_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2594b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_wild_predictions(final_model, TEST_IMAGES_DIR, class_names, TARGET_SIZE)\n",
    "process_and_display_video(VIDEO_PATH, final_model, class_names, TARGET_SIZE)\n",
    "robustness_test(final_model, TEST_SINGLE_IMG_DIR, class_names, TARGET_SIZE)\n",
    "ejecutar_visualizacion_capas(final_model, TEST2_IMAGES_DIR, TARGET_SIZE)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
